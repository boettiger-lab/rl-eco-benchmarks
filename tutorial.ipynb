{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URAP RL tutorial\n",
    "\n",
    "This tutorial explores the basics of how to implement and train RL algorithms using the `rl_eco_benchmarks` package. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL Basics\n",
    "\n",
    "Reinforcement learning algorithms have two conceptual components: an Agent and an Environment. \n",
    "The Agent interacts with the Environment with some goal, and the Environment reacts to the Agent's actions.\n",
    "(Monday Sept. 18th's meeting, I called the Environment a 'system'. Here I'll switch back to the more common term used, 'Environment'.)\n",
    "\n",
    "To recap the reading materials: In each time-step,\n",
    "1. the agent **observes** the environment---that is, it receives some information about the state of the environment,\n",
    "2. the agent **acts** on the environment,\n",
    "3. the environment changes its state accordingly, and the agent receives a **reward** that depends on the action taken, as well as on the corresponding change of environmental state.\n",
    "\n",
    "The basic unit of an RL algorithm is an *Episode*, a sequence of time-steps with a pre-specified maximum length. The goal of the agent is to be able to “play” episodes with high rewards, and especially to avoid episodes with low reward. \n",
    "\n",
    "Alright, so let's go to an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL for Fisheries\n",
    "\n",
    "**Problem context.** The classic example we will work with is the one where 1. the Agent is a fishery that wants to engage in sustainable fishing over a long period of time, and 2. the Environment is a dynamical model for the fish population size. (This model, we will see later on, can include other non-fished populations with which our species interacts.) \n",
    "\n",
    "**Time-steps.** Our time-steps usually represent a year: at the beginning of the fishing year, the agent decides how much fishing it will allow throughout the year, and then we simulate the consequences of that decision. Our episodes will typically have a maximum length of 100 or 200 years, although we typically include a condition that the episode “ends early” if there is a near-extinction. \n",
    "\n",
    "**Dynamical model.** Our dynamical model will be a *discrete time population dynamics model*, for example something of the following form:\n",
    "$$\n",
    "N_{t+1} = N_t + f(N_t, t, a_t),\n",
    "$$\n",
    "where $N_t$ is the population size at time-step $t$, $a_t$ is the action taken by the Agent in that time-step, and $f$ is some function.\n",
    "Notice that we (optionally) include a time dependence in $f$---this can be useful when trying to model the effects of e.g. climate change or habitat loss due to factors external to the ecosystem itself.\n",
    "We will return to this point in a bit.\n",
    "\n",
    "That equation is still a bit abstract, let's get more concrete.\n",
    "A classic model used in fishery science is a model of *logistic growth*, of the form\n",
    "$$\n",
    "N_{t+1} = N_t + r \\times N_t \\times (1-N_t/K) - a_t,\n",
    "$$\n",
    "where $r$ and $K$ are parameters of the model ($r$ is sometimes called a *reproduction rate* as it regulates how the rate at which the population grows, and $K$ is the *carrying capacity* which gives an upper limit to how much the population can grow).\n",
    "\n",
    "**Rewards.** The Agent *fishes out* a mass $a_t$ of fish. We will use a simple way of modelling the economic benefits of having a high harvest: the agent receives a reward of $a_t$. This means that the Agent wants to fish as much as possible---but there is a balance here: because the time window of an episode is long (100-200 years), it can make more sense for the Agent to fish sustainably for a long time than to fish extremely for a short.\n",
    "\n",
    "We include an extra component of the reward function: if at any time-step $N_t < N_{\\text{thresh.}}$ (the population falls below some threshold value), then the episode ends immediatly and a penalty of $-200/t$ is added to the episode reward. This extra component encodes the dire consequences that could come out of a species extinction for the ecosystem as a whole (which could affect the economy in ways beyond the loss of the ability to fish $N$). This term, moreover, helps RL algorithms converge to sustainable solutions faster. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python classes and objects\n",
    "\n",
    "We will run our RL algorithms in Python. There are a couple of basic but key aspects of object-oriented programming (OOP) in Python that we'll need to cover for that.\n",
    "\n",
    "In OOP, the code is organized around 'objects'. These objects have certain qualities (called *properties* of the object) and objects can also perform actions that process data to produce a result (called *methods* of the object). \n",
    "\n",
    "## How to create objects in your code?\n",
    "\n",
    "To create an object within your code, you need to first write the code for the *class* of that object. This code will let the computer know which properties and which methods will the objects of this class have. \n",
    "\n",
    "For example, let's make a class of objects which are a very simple type of chat-bot. The chatbot has two properties: its name, and its general mood (namely, will it be mean or nice to you!). It also has two methods -- both equally useless -- the first one is a greeting, and the second one is a template answer to any question you give it.\n",
    "\n",
    "This is how the code to that chatbot would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chatbot:\n",
    "    def __init__(self, name, mood):\n",
    "        \"\"\"\n",
    "        uses input name and mood to generate the chatbot object.\n",
    "\n",
    "        args:\n",
    "            self = don't worry about it, this is just standard python syntax for classes\n",
    "            name = str\n",
    "            mood = 'nice' or 'mean' (str)\n",
    "        \"\"\"\n",
    "\n",
    "        # make sure that the mood input has one of the accepted values\n",
    "        assert mood in ['nice', 'mean'], \"'mood' variable must have value 'nice' or 'mean'!\"\n",
    "\n",
    "        # define the object properties based on input provided\n",
    "        self.name = name\n",
    "        self.mood = mood\n",
    "    \n",
    "    def greet(self):\n",
    "        \"\"\" you always need to pass 'self' as input to object methods -- just standard Python syntax. \"\"\"\n",
    "        if self.mood == \"nice\":\n",
    "            print(f\"Hi, my name is {self.name}, it's so nice to chat with you! How can I help?\")\n",
    "        if self.mood == \"mean\":\n",
    "            print(f\"Ugh, do you even know who I am? I'm {self.name}, I don't have time for you.\")\n",
    "    \n",
    "    def reply(self, question):\n",
    "        \"\"\" question = str \"\"\"\n",
    "        if self.mood==\"nice\":\n",
    "            print(f\"Thank you so much for your question ({question}). I don't know the answer, but I hope you find out!\")\n",
    "        if self.mood==\"mean\":\n",
    "            print(f\"Lol, '{question}', you're laaame.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the first method that we coded in our class above, `__init__`. This is the method that 'sets up' the object when you create it. Namely, to create it, you will provide two inputs: 'name' and 'mood', with these two inputs the computer knows which type of chatbot to create.\n",
    "\n",
    "## Creating objects once the class is defined\n",
    "\n",
    "Now that we have coded our class, we may instantiate it---that is, we may generate chatbot objects. This is the way we do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot1 = chatbot(name=\"Felipe (the nice one)\", mood=\"nice\")\n",
    "chatbot2 = chatbot(name=\"Felipe (the mean one)\", mood=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the properties of the chatbots and also call their methods in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Felipe (the nice one)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is Felipe (the nice one), it's so nice to chat with you! How can I help?\n"
     ]
    }
   ],
   "source": [
    "chatbot1.greet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lol, 'How are you?', you're laaame.\n"
     ]
    }
   ],
   "source": [
    "chatbot2.reply(question=\"How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 'self' argument...?\n",
    "\n",
    "Notice that when I called the `reply` method, I just provided the question string as an input, *not* this mystery `self` input that was required for defining the method.\n",
    "\n",
    "That's because the `self` argument is the object itself! When you call `chatbot1.greet()`, for example, the argument `self` is `chatbot1`. This 'quirk' of python is a design choice that allows for 'uninstantiated class methods'. I honestly don't know enough about these to understand this design choice, but it won't be relevant to us, and it's just a nuisance to remember to include that `self` argument in all our class methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI gym classes for RL\n",
    "\n",
    "The frameworks we will use for RL are based on so-called OpenAI-gyms. These are classes that have a specific form -- they need to have some standard properties and some standard methods which we will cover below. This standardization is done so that RL optimization algorithms can easily communicate with your custom environment.\n",
    "\n",
    "This is the standard template for a gym environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium) (1.23.5)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium) (4.5.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gymnasium) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "# we need to make sure that the gymnasium package is installed first\n",
    "!pip install gymnasium\n",
    "\n",
    "# now we import the gymnasium package\n",
    "import gymnasium as gym\n",
    "\n",
    "class fishing_env(gym.Env):\n",
    "    \"\"\" we always 'inherit' from the template calss gym.Env in the package gymnasium. \n",
    "        this sets up some basic functionality for our environment class. \n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "        \"\"\" I used the argument '*args' for the moment cause I don't want to commit yet\n",
    "            to which arguments we should provide to the environment.\n",
    "\n",
    "            In this method we will need to define two properties:\n",
    "            self.observation_space\n",
    "            and\n",
    "            self.action_space.\n",
    "\n",
    "            We'll get to that later!\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def reset(self, *, seed=42, options=None):\n",
    "        \"\"\" this method is called to reset the state of the system to an initial value. \n",
    "            the next episode will start by using this initial value.\n",
    "\n",
    "            this method should return the initial state of the environment as an output.\n",
    "\n",
    "            don't worry about the '*, seed=42, options=None' arguments for now, they won't \n",
    "            change for our intents! We'll discuss these a bit though :)\n",
    "        \"\"\"\n",
    "        ...\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\" here, we tell the system how it should react to an action we take. \n",
    "        \n",
    "        the output of this method should be a tuple of the form:\n",
    "        (\n",
    "            system state (array), \n",
    "            reward (float, as a result of the action performed), \n",
    "            terminated (boolean, whether the episode ended with this timestep), \n",
    "            done (boolean, irrelevant for our purposes, we will just set it to be = False)\n",
    "            info (a python dictionary, which we will set to be just the empty dict = {} for simplicity),\n",
    "        )\n",
    "        \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting in some actual content in our environment!\n",
    "\n",
    "Now we will put in some actual code inside of the methods of the `fishing_env` above. This will be mostly on you all to complete the code as necessary in order for the environment to reproduce the behavior that I introduced at the start of the document (the dynamics of the system, the actions available, etc).\n",
    "\n",
    "We will let the episode lengths be 200 time-steps.\n",
    "\n",
    "As a hint, the following code shows what the `__init__` method should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces\n",
    "\n",
    "def __init__(self, init_state):\n",
    "    self.t_max = 200\n",
    "    self.init_state = init_state\n",
    "    self.state = self.reset()\n",
    "\n",
    "    self.observation_space = spaces.Box(\n",
    "            np.array([0]),\n",
    "            np.array([1]),\n",
    "            dtype = np.float32, # use 32-bit floats for more efficiency on GPU computations! >:-)\n",
    "            )\n",
    "\n",
    "    self.action_space = spaces.Box(\n",
    "            np.array([0]),\n",
    "            np.array([1]),\n",
    "            dtype = np.float32,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `observation_space` and `action_space` properties are defined using `gymnasium.spaces.Box` objects. These simply represent 'boxes' of possible numbers. In our case they are 1-D boxes (notice that the first and second arguments to `Box(...)` are arrays corresponding to opposing corners of the box---in our case, the number 0, and the number 1). In a 2-D case, we'd have something such as, for example, \n",
    "```\n",
    "self.observation_space = spaces.Box(\n",
    "            np.array([0,0]),\n",
    "            np.array([1,1]),\n",
    "            dtype = np.float32,\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice also that the `__init__` function has no `return` statement: it is a 'void' function that returns None always. The importance of this function is not the value it returns---as we said before, what is important is what happens when it runs: it *creates* an object with properties and methods which are influenced by the input given. (In this case, the input given is the initial state `init_state`. In the chatbox example, the input given was the chatbot's name and mood.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
